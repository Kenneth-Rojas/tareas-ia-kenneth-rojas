{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLyFT4yAw2XnJARYMTXgWY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kenneth-Rojas/tareas-ia-kenneth-rojas/blob/main/SpamOrHam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorio de Redes Neuronales con PLN\n",
        "El objetivo de este laboratorio es crear un proyecto propio de redes neuronales utilizando técnicas de PLN. Es este caso se utilizará una red profunda con 2 capas ocultas y una capa de salida.\n",
        "\n",
        "Se realiza una clasificación binaria para clasificar mensajes o correos electrónicos en forma de texto como SPAM o HAM (correos no deseados o correos de interés).\n",
        "\n",
        "Proyecto realizado por: Kenneth Rojas Rivera"
      ],
      "metadata": {
        "id": "kR8Cs-xFRi8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Librerias de Python requeridas"
      ],
      "metadata": {
        "id": "TKklxjIDST9t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_raOYojMPE5"
      },
      "outputs": [],
      "source": [
        "!pip install pandas tensorflow scikit-learn imblearn numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procesamiento de texto\n",
        "Primero debemos obtener la base de datos con la que entrenaremos al modelo, para este caso se utilizará el dataset sms.csv el cual contiene una etiqueta de spam o ham seguido del texto."
      ],
      "metadata": {
        "id": "ZSKppoZDTPrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Descargar el dataset (formato: \"label\\tmessage\")\n",
        "url = \"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
        "df = pd.read_csv(url, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "# Convertimos etiquetas a 0 (ham) y 1 (spam)\n",
        "df['label_num'] = df.label.map({'ham': 0, 'spam': 1})\n",
        "\n",
        "X = df['message'].values\n",
        "y = df['label_num'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "PmEMbiM8OIWo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acto seguido es importante tokenizar y vectorizar los datos que extraidos anteriormente, así como también reordenarlos para evitar una gran densidad datos de spam o ham contiguos que puedan sesgar el modelo."
      ],
      "metadata": {
        "id": "GuhNqfoaTqHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X_train_vec, y_train)"
      ],
      "metadata": {
        "id": "pTEigNyiOPEZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Red neuronal profunda\n",
        "Utilizaremos un modelos de capas secuenciales, la primera y segunda capa corresponden a capas ocultas con activacion ReLU. La primera capa de 64 neuronas clasifica los datos de entrada, la segunda capa de 32 neuronas procesa esta clasificacion y las procesa a la capa de salida.\n",
        "\n",
        "La capa de salida consta de una única neurona con activacion tipo sigmod para una clasificación binaria efectiva."
      ],
      "metadata": {
        "id": "2ldq63rBUHZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "model_spam = Sequential()\n",
        "model_spam.add(Dense(64, activation='relu', input_shape=(X_resampled.shape[1],)))\n",
        "model_spam.add(Dense(32, activation='relu'))\n",
        "model_spam.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_spam.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_spam.fit(X_resampled.toarray(), np.array(y_resampled), epochs=15, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DMuICOXeOoSi",
        "outputId": "53d44da5-8f31-4f39-a4ff-a051efaef698"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8259 - loss: 0.4480 - val_accuracy: 0.9987 - val_loss: 0.0182\n",
            "Epoch 2/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
            "Epoch 3/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
            "Epoch 4/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 8.2714e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.1879e-04 - val_accuracy: 1.0000 - val_loss: 6.4785e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.6744e-04 - val_accuracy: 1.0000 - val_loss: 3.5917e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.5756e-04 - val_accuracy: 1.0000 - val_loss: 2.6169e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4574e-04 - val_accuracy: 1.0000 - val_loss: 1.5949e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.3187e-04 - val_accuracy: 1.0000 - val_loss: 1.2310e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.4995e-05 - val_accuracy: 1.0000 - val_loss: 9.6328e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.7121e-05 - val_accuracy: 1.0000 - val_loss: 7.6591e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.5072e-05 - val_accuracy: 1.0000 - val_loss: 5.7884e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.4780e-05 - val_accuracy: 1.0000 - val_loss: 5.0739e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5123e-05 - val_accuracy: 1.0000 - val_loss: 3.8813e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.0637e-05 - val_accuracy: 1.0000 - val_loss: 3.1169e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cdb0f4ef790>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funcion de prediccion\n",
        "Definimos la función de llamado a nuestro modelo de red neuronal profunda donde se evalua la probabilidad de que el texto sea SPAM, la función devuelve las etiquetas SPAM para textos con probabilidad alta y HAM para casos de baja probabilidad."
      ],
      "metadata": {
        "id": "WkMIYpuXVlJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predecir_spam(texto, modelo):\n",
        "    vec = vectorizer.transform([texto])\n",
        "    prob = modelo.predict(vec.toarray())[0][0]\n",
        "    return 'SPAM' if prob >= 0.5 else 'HAM'\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QUDABgd-OvGn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplos de prueba de la red profunda\n",
        "\n",
        "print(predecir_spam(\"Congratulations! You've won a free ticket to Bahamas!\", model_spam))\n",
        "print(predecir_spam(\"WINNER!! You have won a $1000 Walmart gift card. Go to http://bit.ly/123456 to claim now!\", model_spam))\n",
        "print(predecir_spam(\"Hey, are we still meeting at 3pm for coffee?\", model_spam))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg6Z3ObIUyy2",
        "outputId": "281a8411-461c-4c2a-81e8-968b4f2dcd0b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "SPAM\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "SPAM\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "No SPAM\n"
          ]
        }
      ]
    }
  ]
}